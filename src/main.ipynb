{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c8bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasplit import S21SplitByThirds\n",
    "from helpers.pipeline_manager import S21Pipeline\n",
    "from algos.algorithms import S21DecisionTreeClassifier, S21DecisionTreeRegressor, S21RandomForestClassifier, S21GradientBoostingClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c5bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"../datasets/data/training.csv\")\n",
    "\n",
    "splitter = S21SplitByThirds(df)\n",
    "df_train, df_val, df_test = splitter.split()\n",
    "\n",
    "TARGET = \"IsBadBuy\"\n",
    "drop_cols = [TARGET, \"PurchDate\"]\n",
    "\n",
    "X_train = df_train.drop(columns=drop_cols)\n",
    "X_val = df_val.drop(columns=drop_cols)\n",
    "X_test = df_test.drop(columns=drop_cols)\n",
    "\n",
    "y_train = df_train[TARGET]\n",
    "y_val = df_val[TARGET]\n",
    "y_test = df_test[TARGET]\n",
    "\n",
    "Xs = [X_train, X_val, X_test]\n",
    "ys = [y_train, y_val, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3231e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S21DecisionTreeClassifier Gini: 0.42693\n",
      "sklearn DecisionTreeClassifier Gini: 0.42140\n",
      "S21DecisionTreeRegressor Gini: 0.42661\n",
      "S21RandomForestClassifier Gini: 0.46839\n",
      "S21GradientBoostingClassifier Gini: 0.47210\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"S21DecisionTreeClassifier\", S21DecisionTreeClassifier(random_state=42)), # max depth = 7\n",
    "    (\"sklearn DecisionTreeClassifier\", DecisionTreeClassifier(random_state=42, max_depth=7)),\n",
    "    (\"S21DecisionTreeRegressor\", S21DecisionTreeRegressor(random_state=42)),\n",
    "    (\"S21RandomForestClassifier\", S21RandomForestClassifier(random_state=42)),\n",
    "    (\"S21GradientBoostingClassifier\", S21GradientBoostingClassifier(number_of_trees=50, max_depth=3, learning_rate=0.1, random_state=42)),\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    pipeline = S21Pipeline(name, model, Xs, ys)\n",
    "    gini = pipeline.build_evaluate(X_val, y_val)\n",
    "    print(f\"{name} Gini: {gini:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7685e03",
   "metadata": {},
   "source": [
    "Моя имплементация показывает результаты чуть лучше модели из sklearn. Происходит это из-за использования mergesort в методе _find_best_split()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8c8868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LGBMClassifier Gini: 0.48859\n",
      "\n",
      "Best CatBoostClassifier Gini: 0.49391\n",
      "\n",
      "Best XGBClassifier Gini: 0.49297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_configs = {\n",
    "    \"LGBMClassifier\": {\n",
    "        \"estimator_cls\": LGBMClassifier,\n",
    "        \"base_params\": {\n",
    "            \"objective\": \"binary\",\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "            \"subsample_freq\": 1,\n",
    "            \"force_col_wise\": True,\n",
    "            \"verbosity\": -1,\n",
    "        },\n",
    "        \"param_distributions\": {\n",
    "            \"n_estimators\": [250, 400, 550, 700],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.08],\n",
    "            \"num_leaves\": [31, 63, 95],\n",
    "            \"max_depth\": [-1, 10, 16],\n",
    "            \"min_child_samples\": [20, 40, 60],\n",
    "            \"subsample\": [0.7, 0.85, 1.0],\n",
    "            \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "            \"reg_lambda\": [0.0, 1.0, 5.0],\n",
    "        },\n",
    "        \"n_iter\": 12,\n",
    "    },\n",
    "    \"CatBoostClassifier\": {\n",
    "        \"estimator_cls\": CatBoostClassifier,\n",
    "        \"base_params\": {\n",
    "            \"loss_function\": \"Logloss\",\n",
    "            \"eval_metric\": \"AUC\",\n",
    "            \"verbose\": False,\n",
    "            \"allow_writing_files\": False,\n",
    "            \"random_seed\": 42,\n",
    "        },\n",
    "        \"param_distributions\": {\n",
    "            \"iterations\": [300, 500, 700],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.07],\n",
    "            \"depth\": [4, 6, 8],\n",
    "            \"l2_leaf_reg\": [1.0, 3.0, 7.0, 11.0],\n",
    "            \"bagging_temperature\": [0.0, 0.5, 1.0],\n",
    "            \"border_count\": [64, 128, 254],\n",
    "        },\n",
    "        \"n_iter\": 12,\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"estimator_cls\": XGBClassifier,\n",
    "        \"base_params\": {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"use_label_encoder\": False,\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"verbosity\": 0,\n",
    "        },\n",
    "        \"param_distributions\": {\n",
    "            \"n_estimators\": [300, 450, 600],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.08],\n",
    "            \"max_depth\": [4, 6, 8],\n",
    "            \"min_child_weight\": [1, 3, 5],\n",
    "            \"subsample\": [0.7, 0.85, 1.0],\n",
    "            \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "            \"gamma\": [0.0, 0.1, 0.3],\n",
    "            \"reg_lambda\": [1.0, 3.0, 5.0],\n",
    "        },\n",
    "        \"n_iter\": 12,\n",
    "    },\n",
    "}\n",
    "\n",
    "best_pipelines = {}\n",
    "\n",
    "for label, cfg in search_configs.items():\n",
    "    estimator_cls = cfg[\"estimator_cls\"]\n",
    "    base_params = cfg[\"base_params\"]\n",
    "    param_distributions = cfg[\"param_distributions\"]\n",
    "    n_iter = cfg.get(\"n_iter\", 12)\n",
    "\n",
    "    base_model = estimator_cls(**base_params)\n",
    "    pipeline = S21Pipeline(label, base_model, Xs, ys)\n",
    "\n",
    "    best_gini = pipeline.tune_model(\n",
    "        estimator_cls,\n",
    "        base_params=base_params,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        X_eval=X_val,\n",
    "        y_eval=y_val,\n",
    "    )\n",
    "    \n",
    "    best_pipelines[label] = pipeline\n",
    "\n",
    "    print(f\"Best {label} Gini: {best_gini:.5f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26685867",
   "metadata": {},
   "source": [
    "- **LightGBM**: строит деревья листовым способом (leaf-wise), очень быстрый на больших и разреженных данных, но чувствителен к переобучению и требует аккуратной настройки регуляризации и `num_leaves`.\n",
    "- **CatBoost**: использует симметричные деревья и ordered boosting, сразу работает устойчиво, нативно кодирует категориальные признаки и меньше зависит от тонкой настройки гиперпараметров.\n",
    "- **XGBoost**: level-wise градиентный бустинг с большим набором регуляризаций, гибкими функциями потерь, но часто работает медленнее LightGBM и требует ручного кодирования категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9775b",
   "metadata": {},
   "source": [
    "**CatBoost categorical feature**: библиотека сама преобразует категориальные столбцы через статистический (target-based) encoding с приёмом Ordered Target Statistics — для каждого объекта берётся информация только из «прошлых» примеров, добавляется сглаживание priors и генерируются комбинации категорий. Это снижает утечку target и позволяет обрабатывать категориальные признаки без One-Hot. (Conditional Target Rate).\n",
    "\n",
    "**XGBoost DART mode**: режим Dropouts meet Additive Regression Trees. На каждой итерации случайно «выключается» часть уже обученных деревьев (dropout), модель обучается как если бы этих деревьев не было, а затем их веса подстраиваются. Такой стохастический приём напоминает dropout в нейросетях и помогает бороться с переобучением, за счёт параметров `sample_type`, `normalize_type`, `rate_drop`, `skip_drop` можно контролировать долю и способ выключения деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17eb589",
   "metadata": {},
   "source": [
    "Лучший результат среди деревьев с бустингом у CatBoost (gini = 0.49391). Это произошло потому что библиотека хорошо подходит для решения таких задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5122046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train gini: 0.55384, val gini: 0.49391, test_gini: 0.46724\n"
     ]
    }
   ],
   "source": [
    "catboost_pipe = best_pipelines[\"CatBoostClassifier\"]\n",
    "train_gini = catboost_pipe.build_evaluate(X_train, y_train)\n",
    "val_gini = catboost_pipe.build_evaluate(X_val, y_val)\n",
    "test_gini = catboost_pipe.build_evaluate(X_test, y_test)\n",
    "\n",
    "print(f'train gini: {train_gini:.5f}, val gini: {val_gini:.5f}, test_gini: {test_gini:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f272331",
   "metadata": {},
   "source": [
    "Есть небольшое падение метрики, но, думаю некорректно считать это переобучением, так как качество метрики не резко падает, а плавно снижается. В целом, модель достаточно хорошо показывает себя на всех трех датасетах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5723c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S21ExtraTreesClassifier gini: 0.20529\n"
     ]
    }
   ],
   "source": [
    "extra_clf_model = S21RandomForestClassifier(\n",
    "    splitter='random', \n",
    "    bootstrap=False, # disabled subsampling\n",
    "    random_state=42,\n",
    "    max_depth=1 # on purpose\n",
    ")\n",
    "\n",
    "extra_clf_pipeline = S21Pipeline(\"S21ExtraTreesClassifiers\", extra_clf_model, Xs, ys)\n",
    "extra_gini = extra_clf_pipeline.build_evaluate()\n",
    "\n",
    "print(f'S21ExtraTreesClassifier gini: {extra_gini:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd827f82",
   "metadata": {},
   "source": [
    "Результат модели на одиночном дереве > 0.12."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
