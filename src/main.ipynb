{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c8bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasplit import S21SplitByThirds\n",
    "from helpers.pipeline_manager import S21Pipeline\n",
    "from algos.algorithms import S21DecisionTreeClassifier, S21DecisionTreeRegressor, S21RandomForestClassifier, S21GradientBoostingClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c5bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/data/training.csv\")\n",
    "\n",
    "splitter = S21SplitByThirds(df)\n",
    "df_train, df_val, df_test = splitter.split()\n",
    "\n",
    "TARGET = \"IsBadBuy\"\n",
    "drop_cols = [TARGET, \"PurchDate\"]\n",
    "\n",
    "X_train = df_train.drop(columns=drop_cols)\n",
    "X_val = df_val.drop(columns=drop_cols)\n",
    "X_test = df_test.drop(columns=drop_cols)\n",
    "\n",
    "y_train = df_train[TARGET]\n",
    "y_val = df_val[TARGET]\n",
    "y_test = df_test[TARGET]\n",
    "\n",
    "Xs = [X_train, X_val, X_test]\n",
    "ys = [y_train, y_val, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3231e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S21DecisionTreeClassifier Gini: 0.42693\n",
      "sklearn DecisionTreeClassifier Gini: 0.19031\n",
      "S21DecisionTreeRegressor Gini: 0.42661\n",
      "S21RandomForestClassifier Gini: 0.46839\n",
      "S21GradientBoostingClassifier Gini: 0.47210\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"S21DecisionTreeClassifier\", S21DecisionTreeClassifier(random_state=42)),\n",
    "    (\"sklearn DecisionTreeClassifier\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"S21DecisionTreeRegressor\", S21DecisionTreeRegressor(random_state=42)),\n",
    "    (\"S21RandomForestClassifier\", S21RandomForestClassifier(random_state=42)),\n",
    "    (\"S21GradientBoostingClassifier\", S21GradientBoostingClassifier(number_of_trees=50, max_depth=3, learning_rate=0.1, random_state=42)),\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    pipeline = S21Pipeline(name, model, Xs, ys)\n",
    "    gini = pipeline.build_evaluate(X_val, y_val)\n",
    "    print(f\"{name} Gini: {gini:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7685e03",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier из sklearn показывает результаты хуже моей имплементации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1060a16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2607, number of negative: 20452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3605\n",
      "[LightGBM] [Info] Number of data points in the train set: 23059, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113058 -> initscore=-2.059881\n",
      "[LightGBM] [Info] Start training from score -2.059881\n",
      "LGBMClassifier Gini: 0.47834\n",
      "XGBClassifier Gini: 0.48021\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "library_models = [\n",
    "    (\"LGBMClassifier\", LGBMClassifier(n_estimators=200, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, max_depth=-1, random_state=42)),\n",
    "    #(\"CatBoostClassifier\", CatBoostClassifier(iterations=200, learning_rate=0.05, depth=6, random_seed=42, verbose=False, allow_writing_files=False)),\n",
    "    (\"XGBClassifier\", XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8, objective=\"binary:logistic\", eval_metric=\"auc\", reg_lambda=1.0, gamma=0.0, random_state=42, use_label_encoder=False, n_jobs=-1)),\n",
    "]\n",
    "\n",
    "for name, model in library_models:\n",
    "    pipeline = S21Pipeline(name, model, Xs, ys)\n",
    "    gini = pipeline.build_evaluate(X_val, y_val)\n",
    "    print(f\"{name} Gini: {gini:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
